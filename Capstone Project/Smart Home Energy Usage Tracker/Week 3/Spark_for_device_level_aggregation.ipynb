{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "Oaos5sqUL_EF",
        "outputId": "86b95d05-3e68-4e02-ba3d-4b28d65b667b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7eccb45277d0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://66b85d919c7f:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>DeviceAggregation</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "#1. Load a large dataset of sensor logs using PySpark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"DeviceAggregation\").getOrCreate()\n",
        "spark\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load cleaned sensor logs CSV\n",
        "df = spark.read.option(\"header\", \"true\").csv(\"cleaned_energy_logs.csv\", inferSchema=True)\n",
        "\n",
        "# Display sample data\n",
        "df.show(5)\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iT11eq_YRR7I",
        "outputId": "4dd89a00-ae85-46a5-f4f6-5f56f5157639"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------------------+----------+-------+-------+-------+\n",
            "|device_id|          timestamp|energy_kwh|voltage|current|room_id|\n",
            "+---------+-------------------+----------+-------+-------+-------+\n",
            "|        4|2025-05-30 10:12:00|      3.24|  218.5|    4.8|      1|\n",
            "|        7|2025-05-30 11:15:00|      0.75|  221.3|    2.1|      2|\n",
            "|        2|2025-05-30 12:20:00|      1.12|  219.7|    3.3|      3|\n",
            "|        5|2025-05-30 13:25:00|      2.54|  217.9|    5.1|      4|\n",
            "|        1|2025-05-30 14:30:00|       4.1|  222.0|    7.0|      5|\n",
            "+---------+-------------------+----------+-------+-------+-------+\n",
            "only showing top 5 rows\n",
            "\n",
            "root\n",
            " |-- device_id: integer (nullable = true)\n",
            " |-- timestamp: timestamp (nullable = true)\n",
            " |-- energy_kwh: double (nullable = true)\n",
            " |-- voltage: double (nullable = true)\n",
            " |-- current: double (nullable = true)\n",
            " |-- room_id: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2.Group by device and calculate peak vs off-peak usage\n",
        "from pyspark.sql.functions import hour, when, to_timestamp, sum\n",
        "\n",
        "df = df.withColumn(\"timestamp\", to_timestamp(\"timestamp\"))\n",
        "df = df.withColumn(\"hour\", hour(\"timestamp\"))\n",
        "\n",
        "# Classify as Peak (6 PM to 6 AM) or Off-Peak (6 AM to 6 PM)\n",
        "df = df.withColumn(\"usage_period\", when((df[\"hour\"] >= 18) | (df[\"hour\"] < 6), \"Peak\").otherwise(\"Off-Peak\"))\n",
        "\n",
        "# Group by device and period, aggregate total energy\n",
        "peak_offpeak_usage = df.groupBy(\"device_id\", \"usage_period\").agg(\n",
        "    sum(\"energy_kwh\").alias(\"total_energy_kwh\")\n",
        ")\n",
        "\n",
        "peak_offpeak_usage.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6W7QMA6tMcon",
        "outputId": "6e350804-97c7-497e-d0fa-768be9e86a7f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------+----------------+\n",
            "|device_id|usage_period|total_energy_kwh|\n",
            "+---------+------------+----------------+\n",
            "|        7|        Peak|            3.33|\n",
            "|        6|    Off-Peak|            3.95|\n",
            "|        4|        Peak|             2.2|\n",
            "|        2|    Off-Peak|            1.12|\n",
            "|        5|    Off-Peak|            2.54|\n",
            "|        4|    Off-Peak|            3.24|\n",
            "|        8|    Off-Peak|            0.55|\n",
            "|        3|    Off-Peak|            1.75|\n",
            "|        1|    Off-Peak|             4.1|\n",
            "|        7|    Off-Peak|            0.75|\n",
            "+---------+------------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3.Identify top energy-consuming devices\n",
        "\n",
        "top_devices = df.groupBy(\"device_id\").agg(\n",
        "    sum(\"energy_kwh\").alias(\"total_usage_kwh\")\n",
        ").orderBy(\"total_usage_kwh\", ascending=False)\n",
        "\n",
        "top_devices.show(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYYM7JosMpWe",
        "outputId": "ce2cfccd-a3f6-467f-dd56-d34212ed8990"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------------+\n",
            "|device_id|total_usage_kwh|\n",
            "+---------+---------------+\n",
            "|        4|           5.44|\n",
            "|        1|            4.1|\n",
            "|        7|           4.08|\n",
            "|        6|           3.95|\n",
            "|        5|           2.54|\n",
            "|        3|           1.75|\n",
            "|        2|           1.12|\n",
            "|        8|           0.55|\n",
            "+---------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Save the output\n",
        "\n",
        "peak_offpeak_usage.write.option(\"header\", \"true\").mode(\"overwrite\").csv(\"output/peak_offpeak_usage\")\n",
        "top_devices.write.option(\"header\", \"true\").mode(\"overwrite\").csv(\"output/top_energy_devices\")\n"
      ],
      "metadata": {
        "id": "3Z97MVB-Mtft"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}